# ChatStats Backend Architecture Guide

## Overview

ChatStats backend is a FastAPI Python application serving as the data layer for an iMessage analysis app. The backend orchestrates:
- **ETL** from macOS iMessage database (`chat.db`) with continuous live sync
- **AI-powered conversation analysis** via Celery workers (gevent + prefork pools)
- **AI chatbot interface** (separate from iMessage analysis)
- **Context retrieval system** for LLM prompt composition
- **Real-time updates** via dual event systems (EventBus + message_hub)

**Tech Stack:** FastAPI, SQLAlchemy, SQLite (WAL mode), Celery, Redis (split: queue + metrics), LiteLLM

---

## Critical Architectural Truths

### 1. Three-Layer Architecture

**ALWAYS follow this pattern:**

```
Router (API endpoints)
    ↓ calls
Service (business logic)
    ↓ calls
Repository (data access)
```

**Rules:**
- ✅ Routers call services
- ✅ Services call repositories
- ✅ Services call other services
- ❌ Routers NEVER call repositories directly
- ❌ Repositories NEVER call services

**Why:** This layering makes code easy to reason about and test. Even when a service is a thin wrapper, keep the pattern for consistency.

### 2. Two Distinct "Chat" Domains

**⚠️ MOST IMPORTANT: There are TWO completely separate chat systems:**

**iMessage Domain** (historical message analysis):
- `Chat` - An iMessage conversation thread (one-on-one or group chat)
- `Message` - Individual iMessage messages
- `Conversation` - Temporal grouping of messages (90-minute gaps create new conversations)
- `Contact` - People in your iMessage contacts

**AI Chatbot Domain** (AI assistant interface):
- `ChatbotThread` - An AI conversation thread (was `ChatbotChat`, renamed for clarity)
- `ChatbotMessage` - Messages in AI conversation (user and assistant)
- `ChatbotDocument` - Artifacts/documents generated by AI
- `ChatbotUser` - Users of the AI chatbot

**Golden Rule:** When you see `chat_id`, determine which domain you're in:
- If in `routers/chatbot/` or dealing with `ChatbotThread` → AI chatbot domain
- If in `routers/chats/`, `routers/analysis/`, or dealing with `Chat` → iMessage domain

### 3. Logging Architecture

**⚠️ CRITICAL: Backend logs flow through a specific pipeline to reach Electron console.**

**The Correct Way to Log:**
```python
import logging
logger = logging.getLogger(__name__)

# Use standard Python logging - NO special imports needed
logger.info("Something happened")
logger.error("Something failed", extra={"context": "value"})
```

**How It Works:**

1. Backend Python code uses standard `logging.getLogger(__name__)`
2. `backend/config/logging.py` configures root logger to write to stdout/stderr
3. Electron spawns backend as child process and captures stdout/stderr with `pipeLines()`
4. `pipeLines()` forwards each line to electron-log with scope prefix
5. Logs appear in Electron console

**DON'T:**

- ❌ Try to import electron-log in Python
- ❌ Add IPC calls to send logs
- ❌ Use `print()` instead of logging
- ❌ Try to write directly to electron-log files

**DO:**

- ✅ Use `logging.getLogger(__name__)`
- ✅ Use appropriate log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- ✅ Add structured context with `extra={}` parameter
- ✅ Trust that logs will flow through stdout → Electron → electron-log

**Log Levels:**

- Backend defaults to INFO
- Third-party libraries (httpx, celery, litellm) set to WARNING to reduce noise
- ERROR+ also duplicated to stderr for reliability

### 4. Database Queries: Raw SQL Only

**⚠️ CRITICAL: Always use raw SQL, never ORM query methods.**

**The Right Way:**
```python
from backend.db.session_manager import db
from backend.db.sql import fetch_one, fetch_all, execute_write

with db.session_scope() as session:
    # Fetch single row
    result = fetch_one(session, "SELECT * FROM chats WHERE id = :id", {"id": chat_id})
    
    # Fetch multiple rows
    results = fetch_all(session, "SELECT * FROM messages WHERE chat_id = :chat_id", {"chat_id": chat_id})
    
    # Write operations (with automatic SQLite lock retry)
    execute_write(session, "UPDATE chats SET wrapped_done = true WHERE id = :id", {"id": chat_id})
```

**Why Raw SQL:**

- ORM queries cause functional and performance issues
- Raw SQL is explicit and predictable
- `db.sql` helpers handle SQLite locking automatically
- ORM models are fine for schema definitions, just not queries

**DON'T:**

- ❌ Use `session.query(Model).filter(...)`
- ❌ Use ORM relationship traversal for queries
- ❌ Use `session.add()` / `session.merge()` (use INSERT/UPDATE SQL instead)

**DO:**

- ✅ Always use `db.sql.fetch_one()`, `fetch_all()`, `execute_write()`
- ✅ Write explicit SQL with named parameters
- ✅ Use ORM models for type hints and schema

### 5. Session Management

**Pattern:**
```python
from backend.db.session_manager import db

# ALWAYS use context manager
with db.session_scope() as session:
    # Your database operations here
    # Commits automatically on success, rolls back on exception
    pass
```

**Key Points:**

- Each `session_scope()` creates a NEW session (not cached/thread-local)
- Sessions auto-commit on success, auto-rollback on exception
- Always close promptly to avoid connection pool exhaustion
- In Celery tasks with high concurrency, this pattern is critical

### 6. Database Models Organization

**File Structure:**

- `db/etl_models.py` - iMessage domain (Chat, Message, Conversation, Contact)
- `db/models.py` - AI chatbot domain (ChatbotThread, ChatbotMessage, etc.) + analysis models
- `db/context_models.py` - LLM prompt/report system (PromptTemplate, Report, etc.)
- `db/base.py` - Shared SQLAlchemy Base

All models ultimately use the same Base from `db/base.py`.

**Context Tracking Tables** (created October 2025):

Two junction tables track source context for threads and documents:

- `thread_contexts` - Tracks which iMessage chats/contacts are being analyzed in each Eve thread
- `document_contexts` - Snapshots thread contexts when documents are created

**Why separate tables?**
- Threads can have contexts updated as conversation evolves
- Documents preserve context at creation time (immutable snapshot)
- Allows documents to outlive their origin threads
- Enables inbox UI to show "Analyzing: Casey Adams" instead of "System"

**See:** `routers/agents.md` sections 4-5 for detailed implementation patterns.

---

## Startup Sequence

When the FastAPI app starts (`main.py` → `create_app()` → `@app.on_event("startup")`):

1. **Database Migrations** - `await database.apply_migrations()`
   - Runs Alembic migrations in threadpool
   - ⚠️ CRITICAL: If this fails, app should NOT start
   - Migration errors are now CRITICALLY LOUD (logged with banners + stderr)

2. **Database Seeding** - `await database.seed()`
   - Seeds context definitions and prompt templates
   - Failures logged but don't block startup

3. **Celery Health Check** - `celery_check.schedule()`
   - Background task to verify broker connectivity
   - Non-blocking

4. **Live Sync** - `await live_sync.start()`
   - Initializes watermarks for iMessage WAL watching
   - Starts background task to sync new messages

5. **FAISS Index** - `maybe_rebuild_faiss_index_task.apply_async()`
   - Fire-and-forget background task
   - Rebuilds embedding search index if needed

If any critical step fails (especially migrations), the error should be CRITICALLY LOUD.

---

## Conversation Analysis Pipeline

**Complete flow from message → analysis:**

```
1. New messages arrive via live sync
   ↓
2. ETL creates/updates conversation records
   ↓
3. live_analysis_task triggered
   ↓
4. trigger_analysis_pass (live passes: commitments_live, basic_live)
   ↓
5. [User stops messaging - 90-minute gap]
   ↓
6. check_and_seal_conversations (periodic task, every 60s)
   ↓
7. handle_sealed_conversation
   ↓
8. ETL runs again to finalize conversation
   ↓
9. Publishes conversation_ready_for_analysis event
   ↓
10. handle_conversation_ready
    ↓
11. trigger_analysis_pass (batch passes: basic)
```

**Key details:**
- **Live passes** run immediately on new messages (e.g., `basic_live`, `commitments_live`)
- **Batch passes** run after conversation is sealed (90-min gap)
- **ALL chats get analysis** (no subscription check)
- **Sealing** is triggered by `conversation_tracker` in ETL layer
- **Two-stage analysis:** `call_llm_task` (network) → `persist_result_task` (database)

**See:** `celery_service/agents.md` for detailed task patterns and `docs/conversation_event_system.md` for event flow.

---

## Open Questions & TODOs

### Critical Open Questions

1. **Thread Naming Consistency**
   - Backend models renamed: `ChatbotChat` → `ChatbotThread`
   - Table name kept as `chatbot_chats` for backward compatibility
   - UI refers to these as "threads"
   - See ADR-003 for naming convention decision
   - **Status:** Accepted as-is (model vs table name mismatch intentional)

2. **Frontend Database Access** ✅ RESOLVED (2025-10-06)
   - **Verified:** Frontend has NO direct database access
   - `sqlite3` and `redis` in frontend `package.json` are transitive dependencies only
   - All DB operations go through FastAPI backend HTTP API
   - `lib/chatbot/db/queries.ts` is an HTTP client, NOT direct DB access
   - **Action:** Update frontend documentation to clarify this

3. **Documentation Accuracy**
   - `docs/conversation_event_system.md` - Verify accuracy when we see related code
   - `routers/commitments/two_stage_processing.md` - Accurate, now colocated with code

### ✅ Newly Resolved (2025-10-06)

4. **Progress Tracking Pattern** ✅
   - **Both patterns actively used** in different contexts:
     - `redis_counters.py` (direct) - Used in routers/progress endpoints (10 imports)
     - `counter_buffer.py` (buffered) - Used in Celery tasks (6 imports)
   - **Pattern:**
     - Use `redis_counters` for API endpoints (real-time reads)
     - Use `counter_buffer` for Celery tasks (batched writes, performance)
   - **Documented in:** `services/analysis/agents.md`

5. **Event Publishing Pattern** ✅
   - **EventBus.publish() used directly** (12 usages)
   - **Service wrappers rarely used** (1 usage)
   - **Pattern:** Always use `EventBus.publish()` directly, wrappers are legacy
   - **Documented in:** `services/agents.md` and `EVENT_SYSTEMS.md`

6. **Document Reads Table** ✅
   - **Two tables exist:**
     - `chatbot_document_reads` - Legacy (user-scoped)
     - `chatbot_document_reads_simple` - Current (userless)
   - **Current usage:**
     - `DocumentReadsRepository` uses old table name `chatbot_document_reads`
     - `routers/chatbot/documents.py` uses `chatbot_document_reads_simple`
   - **Action:** Migration exists (20250927_userless_reads.py) to migrate data
   - **Status:** Both tables in use, migration path established

---

## ✅ Resolved Open Questions

**Context Retrieval Consolidation** - COMPLETED ✅
- Legacy `catalog/` system removed entirely
- Deprecated retrieval functions deleted (`chat_analyses`, `contact_analyses`, `self_analyses`)
- All retrieval functions consolidated to `services/context/retrieval/`
- Modern retrievers: `convos`, `analyses` (flexible, token-aware)
- Simple retrievers: `artifacts`, `raw_conversation`, `chat_text`, `user_name`
- See `services/context/agents.md` for detailed usage guide (open questions to be answered)

**LLM System Consolidation** - COMPLETED ✅
- `llm_lite/` moved to `services/llm/`
- Direct provider clients moved to `services/llm/providers/` (for specialized features)
- Old `services/core/llm.py` wrapper removed
- Unified completion logic via LiteLLM
- Compatibility maintained via `LLMService`, `LLMConfigResolver`, `LLMError` wrappers

**Import Path Changes:** If you see old imports during development:
- ❌ `from backend.llm.*` → ✅ `from backend.services.llm.*`
- All old imports were fixed during cleanup phase

**Seed Data & Prompt Migration** - COMPLETED ✅
- **Prompts:** Fully migrated to Eve (context packs in `app/eve/context-packs/`)
  - Legacy `seed_data/prompts/` directory removed (2025-10-27)
  - All analysis passes now use `eve_prompt_id` (no fallback to DB templates)
- **Context definitions:** Still seeded from `seed_data/context_definitions.yaml`
  - Maps retrieval function names to implementations
  - 6 active definitions (Convos, Analyses, Artifacts, RawConversation, ChatText, UserName)
  - Orchestrator in `seed_data/seed_data.py`

**Event Systems Investigation** - COMPLETED ✅
- Two separate event systems identified and documented:
  - **EventBus** (Redis Streams) - Backend-to-backend, analysis progress, task lifecycle
  - **message_hub** (In-process pub/sub) - Real-time UI updates (messages, chats, contacts)
- Complete event type catalog created
- All SSE endpoints mapped (6 endpoints total)
- Usage patterns and anti-patterns documented
- **See:** `EVENT_SYSTEMS.md` for complete reference

**Reports Cleanup** - COMPLETED ✅
- **All report routers deleted**: `generation.py`, `display.py`, `publishing.py`, `task_generation.py`, `cost_estimation.py`, `compile.py`
- **Entire `routers/reports/` directory deleted**
- **Report services deleted**: `workflow.py`, `display.py`, `llm.py`, `cost.py`
- **Report repositories deleted**: `reports.py`, `displays.py`, `published_reports.py`
- **Celery tasks deleted**: `generate_report.py`, `generate_display.py`, `generate_report_with_display.py`
- **Remaining (actively used):**
  - `services/reports/persist.py` - `ReportEventsService` (used by chatbot for SSE events)
  - `services/reports/prompt.py` - `ReportPromptService` (used by contexts router)
- **TODO:** Consider renaming:
  - `ReportEventsService` → `EventService` or `ChatbotEventsService`
  - `ReportPromptService` → `PromptService` (or merge into `services/prompt.py`)

**Migration Chain Fixes** - COMPLETED ✅
- Fixed broken migration reference: `f234fb832e9f` now points to correct parent `702d4ce46e13`
- Deleted duplicate migration: `d91fbd42b505_restore_historic_analysis_status_table.py`
- Migration chain now has single HEAD with proper branching/merging

**Deprecated Features Stubbed** - COMPLETED ✅
- `WrappedAnalysisService` - All methods return deprecation errors
- `CatalogService` wrapped analysis methods - Return deprecation errors
- `StatsRepository` endpoints - Return deprecation messages
- Legacy code kept to avoid crashes, returns clear error messages

---

### Review During Frontend/Celery Phases

7. **Analysis Router Endpoints - Which Are Active?**
   - Many analysis endpoints exist, some may be unused
   - Deprecated endpoint stubbed: `/api/overview` (StatsRepository removed)
   - **Action:** Audit during frontend phase which are actually called

8. **Chatbot Repositories - Missing Entirely** ✅ CLARIFIED (2025-10-06)
   - **Frontend has NO direct DB access** (verified)
   - Tables accessed via Next.js API routes (chatbot/chat, chatbot/documents)
   - API routes use raw SQL (following project preference)
   - **Decision:** Keep raw SQL in API routes, no repositories needed
   - See frontend `lib/chatbot/db/queries.ts` - it's an HTTP client, not DB access

9. **Repository Method Usage Audit**
   - Many repositories have 10-20+ methods, not all actively used
   - Examples: `ConversationRepository.get_conversations_by_date_range()`, etc.
   - **Action:** Cross-reference with services layer to identify unused methods (low priority)

---

## Testing Status

**⚠️ There are NO tests in the backend.**

- Test infrastructure was removed (incomplete/outdated)
- Don't add test-related imports or patterns
- Testing strategy TBD for future

---

## Configuration

All configuration via Pydantic settings in `backend/config/__init__.py`:

```python
from backend.config import settings

settings.debug           # Enable debug mode
settings.log_level       # Root log level (INFO/DEBUG/etc.)
settings.app_dir         # Application data directory
settings.db_path         # SQLite database location
settings.broker_type     # redis | lavinmq
settings.broker_url      # Broker connection URL
```

Environment variables use `CHATSTATS_` prefix:

```bash
CHATSTATS_DEBUG=1
CHATSTATS_LOG_LEVEL=DEBUG
CHATSTATS_BROKER_URL=redis://localhost:6379/0
```

---

## Key Patterns

### Adding a New Router

1. Create router file in appropriate `routers/` subdirectory
2. Import and register in `main.py`:

```python
from backend.routers.yourmodule import router as your_router

router_specs = [
    # ... existing routers ...
    (your_router, "/api/your-path", {"tags": ["your-tag"]}),
]
```

### Database Migrations

Creating a new migration:

```bash
cd app/backend
alembic revision -m "description"
# Edit the generated migration file
alembic upgrade head  # Test locally
```

**Migration fails?** Check:

- Logs in `APP_DIR/backend.log`
- Stderr output (should be CRITICALLY visible if properly logged)
- SQLite WAL files locked? Try restarting Electron

### Adding Context Retrieval Functions

**Pattern:** (To be fleshed out as we explore `retrieval/` code)

- Context definitions in `db/context_models.py`
- Retrieval functions reference in `retrieval_function_ref` column
- (More details coming as we document `retrieval/` and `services/` layers)

---

## Common Pitfalls

- **Using wrong "chat" domain** - Always verify if you're in iMessage or AI chatbot context
- **Using ORM queries** - Use raw SQL with `db.sql` helpers instead
- **Wrong logging approach** - Use standard Python logging, trust the pipeline
- **Not using session_scope()** - Always use context manager for DB sessions
- **Assuming migrations will log loudly** - They now do! (Critical errors with banners)

---

## File Structure Quick Reference

```
app/backend/
├── main.py                    # FastAPI app entry point
├── config/
│   ├── __init__.py           # Unified Pydantic settings
│   └── logging.py            # Root logger configuration
├── db/
│   ├── base.py               # Shared SQLAlchemy Base
│   ├── database.py           # Engine and session factory init
│   ├── session_manager.py    # SessionManager singleton
│   ├── etl_models.py         # iMessage domain models
│   ├── models.py             # Chatbot + analysis models + re-exports
│   ├── context_models.py     # Prompt/report system models
│   └── sql.py                # Raw SQL helpers (use these!)
├── seed_data/                # Database seeding (all in one place)
│   ├── seed_data.py          # Orchestrator
│   ├── context_definitions.yaml  # Context definitions (6 active)
│   └── prompts/              # Prompt templates (filesystem-based)
│       ├── seeder.py
│       └── [prompt directories]
├── startup/
│   ├── database.py           # Migration and seed runners
│   ├── celery_check.py       # Broker health check
│   ├── live_sync.py          # iMessage WAL watcher init
│   └── monitor.py            # Parent process watchdog
├── routers/                  # API endpoints by domain → [agents.md](./routers/agents.md)
├── services/                 # Business logic layer → [agents.md](./services/agents.md)
├── repositories/             # Data access patterns → [agents.md](./repositories/agents.md)
├── celery_service/           # Async task workers → [agents.md](./celery_service/agents.md)
├── etl/                      # iMessage data import → [agents.md](./etl/agents.md)
├── docs/                     # Additional documentation
│   └── conversation_event_system.md
└── EVENT_SYSTEMS.md          # Event system reference guide
```

---

## Layer-Specific Documentation

For detailed information about each layer, see:

### Core Layers
- **[Routers Layer](./routers/agents.md)** - API endpoints, SSE patterns, Celery queuing
- **[Services Layer](./services/agents.md)** - Business logic, workflows, LLM integration
  - [Context System](./services/context/agents.md) - Context retrieval functions
- **[Repositories Layer](./repositories/agents.md)** - Data access, raw SQL patterns

### Async & Data Layers
- **[Celery Service](./celery_service/agents.md)** - Task patterns, analysis passes, bulk operations
- **[ETL Layer](./etl/agents.md)** - Live sync, conversation tracking, import modes

### System Guides
- **[Event Systems Guide](./EVENT_SYSTEMS.md)** - EventBus vs message_hub, SSE endpoints
- **[Conversation Event System](./docs/conversation_event_system.md)** - Event flow details
- **[Seeding Guide](./seed_data/SEEDING_PARITY_CHECK.md)** - Database seeding verification

### Cross-Layer Documentation
- **[App Overview](../agents.md)** - Top-level architecture across all layers
- **[Electron Layer](../electron/agents.md)** - How backend integrates with Electron
